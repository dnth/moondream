{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239339b9974d4ced8fcdf4b1591ef72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:cuda\n",
      "Type: torch.float16\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from moondream_model import VisionEncoder, TextModel\n",
    "import torch \n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "model_path = snapshot_download(\"vikhyatk/moondream1\")\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "DTYPE = torch.float16\n",
    "\n",
    "vision_encoder = VisionEncoder(model_path).to(DEVICE, dtype=DTYPE)\n",
    "text_model = TextModel(model_path).to(DEVICE, dtype=DTYPE)\n",
    "\n",
    "print(f\"Using:{DEVICE}\")\n",
    "print(f\"Type: {DTYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image, prompt, max_new_tokens=128):\n",
    "    with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "        image_embeds = vision_encoder(image)\n",
    "        result = text_model.answer_question(image_embeds, \n",
    "                                            prompt, \n",
    "                                            max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    if isinstance(result, tuple):\n",
    "        result_text = result[0]\n",
    "    else:\n",
    "        result_text = result\n",
    "\n",
    "    # Convert the result to string if it's not already\n",
    "    if not isinstance(result_text, str):\n",
    "        if torch.is_tensor(result_text):\n",
    "            result_text = result_text.cpu().numpy().tolist()\n",
    "            result_text = ' '.join(map(str, result_text))\n",
    "        else:\n",
    "            result_text = str(result_text)\n",
    "\n",
    "    # Apply regex to clean up the result string\n",
    "    cleaned_result = re.sub(\"<$\", \"\", re.sub(\"END$\", \"\", result_text))\n",
    "    return cleaned_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"img/output_000017.jpg\")\n",
    "prompt = \"Describe this image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time took 0.42591166496276855 seconds.\n",
      "Inference time took 0.4257669448852539 seconds.\n",
      "Inference time took 0.41782665252685547 seconds.\n",
      "Inference time took 0.4163053035736084 seconds.\n",
      "Inference time took 0.42008137702941895 seconds.\n",
      "Inference time took 0.4188261032104492 seconds.\n",
      "Inference time took 0.4212477207183838 seconds.\n",
      "Inference time took 0.41730237007141113 seconds.\n",
      "428 ms ± 3.01 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = run_inference(img, prompt, max_new_tokens=20)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moondream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
