{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239339b9974d4ced8fcdf4b1591ef72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:cuda\n",
      "Type: torch.float16\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from moondream_model import VisionEncoder, TextModel\n",
    "import torch \n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "model_path = snapshot_download(\"vikhyatk/moondream1\")\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "DTYPE = torch.float16\n",
    "\n",
    "vision_encoder = VisionEncoder(model_path).to(DEVICE, dtype=DTYPE)\n",
    "text_model = TextModel(model_path).to(DEVICE, dtype=DTYPE)\n",
    "\n",
    "print(f\"Using:{DEVICE}\")\n",
    "print(f\"Type: {DTYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image, prompt, max_new_tokens=128):\n",
    "    with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "        image_embeds = vision_encoder(image)\n",
    "        result = text_model.answer_question(image_embeds, \n",
    "                                            prompt, \n",
    "                                            max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    if isinstance(result, tuple):\n",
    "        result_text = result[0]\n",
    "    else:\n",
    "        result_text = result\n",
    "\n",
    "    # Convert the result to string if it's not already\n",
    "    if not isinstance(result_text, str):\n",
    "        if torch.is_tensor(result_text):\n",
    "            result_text = result_text.cpu().numpy().tolist()\n",
    "            result_text = ' '.join(map(str, result_text))\n",
    "        else:\n",
    "            result_text = str(result_text)\n",
    "\n",
    "    # Apply regex to clean up the result string\n",
    "    cleaned_result = re.sub(\"<$\", \"\", re.sub(\"END$\", \"\", result_text))\n",
    "    return cleaned_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"img/output_000017.jpg\")\n",
    "prompt = \"Describe this image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time took 0.4325826168060303 seconds.\n",
      "Inference time took 0.4155430793762207 seconds.\n",
      "Inference time took 0.4183518886566162 seconds.\n",
      "Inference time took 0.41522932052612305 seconds.\n",
      "Inference time took 0.4229412078857422 seconds.\n",
      "Inference time took 0.42305660247802734 seconds.\n",
      "Inference time took 0.42485737800598145 seconds.\n",
      "Inference time took 0.4246826171875 seconds.\n",
      "429 ms ± 4.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = run_inference(img, prompt, max_new_tokens=20)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moondream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
